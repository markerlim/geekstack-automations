name: Run Gundam Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '0 15 * * *'  # Runs daily at 15:00 UTC

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install beautifulsoup4 requests pymongo google-cloud-storage

    - name: Setup GCP Credentials
      run: |
        echo '${{ secrets.GCP_CREDENTIALS }}' > gcp-credentials.json
        echo "GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-credentials.json" >> $GITHUB_ENV

    - name: Run Gundam scraper
      env:
        MONGO_DATABASE: ${{ secrets.MONGO_DATABASE }}
        MONGO_USER: ${{ secrets.MONGO_USER }}
        MONGO_PASSWORD: ${{ secrets.MONGO_PASSWORD }}
        MONGO_CLUSTER: ${{ secrets.MONGO_CLUSTER }}
        C_GUNDAM: ${{ vars.C_GUNDAM }}  # Make sure to set this variable in your repo settings
        GCSIMAGE: ${{ secrets.GCSIMAGE }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python scrapers/gundam/gcgcheckscrape.py
